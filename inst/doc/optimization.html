<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Optimization</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Optimization</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(galamm)</span></code></pre></div>
<p>The purpose of this vignette is to describe the optimization
procedure used by <code>galamm</code>, and what kind of tools one can
use in the case of convergence issues.</p>
<div id="high-level-overview" class="section level2">
<h2>High-Level Overview</h2>
<p>The optimization procedure used by <code>galamm</code> is described
in Section 3 of <span class="citation">Sørensen, Fjell, and Walhovd (<a href="#ref-sorensenLongitudinalModelingAgeDependent2023">2023</a>)</span>.
It consists of two steps:</p>
<ul>
<li><p>In the inner loop, the marginal likelihood is evaluated at a
given set of parameters. The marginal likelihood is what you obtain by
integrating out the random effects, and this integration is done with
the Laplace approximation. The Laplace approximation yields a large
system of equations that needs to be solved iteratively, except in the
case with conditionally Gaussian responses and unit link function, for
which a single step is sufficient to solve the system. When written in
matrix-vector form, this system of equations will in most cases have an
overwhelming majority of zeros, and to avoid wasting memory and time on
storing and multiplying zero, we use sparse matrix methods.</p></li>
<li><p>In the outer loop, we try to find the parameters that maximize
the marginal likelihood. For each new set of parameters, the whole
procedure in the inner loop has to be repeated. By default, we use the
limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm with box
constraints <span class="citation">(<a href="#ref-byrdLimitedMemoryAlgorithm1995">Byrd et al. 1995</a>)</span>,
abbreviated L-BFGS-B. In particular, we use the implementation in R’s
<code>optim()</code> function, which is obtained by setting
<code>method = &quot;L-BFGS-B&quot;</code>. L-BFGS-B requires first derivatives,
and these are obtained by automatic differentiation <span class="citation">(<a href="#ref-skaugAutomaticDifferentiationFacilitate2002">Skaug
2002</a>)</span>. In most use cases of <code>galamm</code>, we also use
constraints on some of the parameters, e.g., to ensure that variances
are non-negative. As an alternative, the Nelder-Mead algorithm with box
constraints <span class="citation">(<a href="#ref-batesFittingLinearMixedEffects2015">Bates et al. 2015</a>; <a href="#ref-nelderSimplexMethodFunction1965">Nelder and Mead
1965</a>)</span> from <code>lme4</code> is also available. Since the
Nelder-Mead algorithm is derivative free, automatic differentiation is
not used in this case, except for computing the Hessian matrix at the
final step.</p></li>
</ul>
<p>At convergence, the Hessian matrix of second derivatives is computed
exactly, again using automatic differentiation. The inverse of this
matrix is the covariance matrix of the parameter estimates, and is used
to compute Wald type confidence intervals.</p>
</div>
<div id="modifying-the-l-bfgs-b-algorithm" class="section level2">
<h2>Modifying the L-BFGS-B algorithm</h2>
<p>We will illustrate some ways of modifying the optimization procedure
with the covariate measurement model example shown in the <a href="https://lcbc-uio.github.io/galamm/articles/mixed_response.html">vignette
on models with mixed response types</a>. Here we start by simply setting
up what we need to fit the model.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>loading_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="cn">NA</span>), <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>families <span class="ot">&lt;-</span> <span class="fu">c</span>(gaussian, binomial)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>family_mapping <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(diet<span class="sc">$</span>item <span class="sc">==</span> <span class="st">&quot;chd&quot;</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>formula <span class="ot">&lt;-</span> y <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> chd <span class="sc">+</span> (age <span class="sc">*</span> bus)<span class="sc">:</span>chd <span class="sc">+</span> fiber <span class="sc">+</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>  (age <span class="sc">*</span> bus)<span class="sc">:</span>fiber <span class="sc">+</span> fiber2 <span class="sc">+</span> (<span class="dv">0</span> <span class="sc">+</span> loading <span class="sc">|</span> id)</span></code></pre></div>
<p>Fitting the model with default arguments yields a warning when we
look at the summary object.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">galamm</span>(</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>  <span class="at">data =</span> diet,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>  <span class="at">family =</span> families,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  <span class="at">family_mapping =</span> family_mapping,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>  <span class="at">factor =</span> <span class="fu">list</span>(<span class="st">&quot;loading&quot;</span>),</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>  <span class="at">load.var =</span> <span class="st">&quot;item&quot;</span>,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">list</span>(loading_matrix)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(object, parm = &quot;lambda&quot;): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(object, &quot;beta&quot;): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co">#&gt; Formula: formula</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">#&gt;    Data: diet</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt;   2837.6   2892.9  -1406.8  12529.3      730 </span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co">#&gt; Scaled residuals: </span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="co">#&gt; -10.1375  -0.4389  -0.3522   0.2743  27.3350 </span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a><span class="co">#&gt; Lambda:</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="co">#&gt;         loading SE</span></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a><span class="co">#&gt; lambda1   1.000  .</span></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a><span class="co">#&gt; lambda2   1.000  .</span></span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a><span class="co">#&gt; lambda3  -2.026  .</span></span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a><span class="co">#&gt; Random effects:</span></span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a><span class="co">#&gt;  Groups Name    Variance Std.Dev.</span></span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a><span class="co">#&gt;  id     loading 0        0       </span></span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a><span class="co">#&gt; Number of obs: 742, groups:  id, 333</span></span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a><span class="co">#&gt; Fixed effects:</span></span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a><span class="co">#&gt; chd           -1.78692         NA      NA       NA</span></span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a><span class="co">#&gt; fiber         17.96184         NA      NA       NA</span></span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a><span class="co">#&gt; fiber2        -0.64927         NA      NA       NA</span></span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a><span class="co">#&gt; chd:age        0.06682         NA      NA       NA</span></span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a><span class="co">#&gt; chd:bus       -0.06882         NA      NA       NA</span></span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a><span class="co">#&gt; fiber:age     -0.20480         NA      NA       NA</span></span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a><span class="co">#&gt; fiber:bus     -1.69601         NA      NA       NA</span></span>
<span id="cb3-45"><a href="#cb3-45" tabindex="-1"></a><span class="co">#&gt; chd:age:bus   -0.04934         NA      NA       NA</span></span>
<span id="cb3-46"><a href="#cb3-46" tabindex="-1"></a><span class="co">#&gt; fiber:age:bus  0.16097         NA      NA       NA</span></span></code></pre></div>
<p>In this case, we can increase the amount of information provided by
<code>optim</code>, with the <code>trace</code> argument. To avoid
getting too much output, we also reduce the number of iterations. We set
the <code>control</code> argument as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">galamm_control</span>(<span class="at">optim_control =</span> <span class="fu">list</span>(<span class="at">maxit =</span> <span class="dv">5</span>, <span class="at">trace =</span> <span class="dv">3</span>, <span class="at">REPORT =</span> <span class="dv">1</span>))</span></code></pre></div>
<p>Here, <code>maxit = 5</code> means that we take at most 5 iterations,
<code>trace = 3</code> means that we want more information from
L-BFGS-B, and <code>REPORT= = 1</code> means that we want L-BFGS-B to
report information at each step it takes. We provide this object to the
<code>control</code> argument in <code>galamm</code>, and rerun the
model:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">galamm</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  <span class="at">data =</span> diet,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="at">family =</span> families,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>  <span class="at">family_mapping =</span> family_mapping,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>  <span class="at">factor =</span> <span class="fu">list</span>(<span class="st">&quot;loading&quot;</span>),</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>  <span class="at">load.var =</span> <span class="st">&quot;item&quot;</span>,</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">list</span>(loading_matrix),</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>  <span class="at">control =</span> control</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt; N = 11, M = 20 machine precision = 2.22045e-16</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; At iterate     0  f=         2148  |proj g|=       122.68</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; At iterate     1  f =       2132.1  |proj g|=        275.51</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; At iterate     2  f =       2100.1  |proj g|=         193.7</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt; At iterate     3  f =       1975.6  |proj g|=        177.11</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; At iterate     4  f =       1923.2  |proj g|=         165.7</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; At iterate     5  f =       1898.8  |proj g|=        83.839</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="co">#&gt; At iterate     6  f =       1887.9  |proj g|=        49.147</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="co">#&gt; final  value 1887.871646 </span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="co">#&gt; stopped after 6 iterations</span></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="fu">vcov</span>(mod)</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(mod): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a><span class="co">#&gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]</span></span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a><span class="co">#&gt;  [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a><span class="co">#&gt;  [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a><span class="co">#&gt;  [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a><span class="co">#&gt;  [4,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a><span class="co">#&gt;  [5,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a><span class="co">#&gt;  [6,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a><span class="co">#&gt;  [7,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a><span class="co">#&gt;  [8,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a><span class="co">#&gt;  [9,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span></code></pre></div>
<p>Since what we did was simply to turn in more reporting, it is no
surprise that the Hessian is still rank deficient, but from the output,
it is also clear that there are no obvious errors, like values that
diverge to infinity. The latter may also happen from time to time.</p>
<p>By default, L-BFGS-B uses the last 5 evaluations of the gradient to
approximate the Hessian that is used during optimization (not to be
confused with the exact Hessian compute with automatic differentiation
after convergence). We try to increase this to 25, and see if that makes
a difference. This is done with the <code>lmm</code> argument. We also
reduce the amount of reporting to be every 10th step, and avoid setting
the maximum number of iterations, which means that
<code>optim()</code>’s default option is used.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">galamm_control</span>(<span class="at">optim_control =</span> <span class="fu">list</span>(<span class="at">trace =</span> <span class="dv">3</span>, <span class="at">REPORT =</span> <span class="dv">10</span>, <span class="at">lmm =</span> <span class="dv">25</span>))</span></code></pre></div>
<p>It is clear that neither this solved the issue.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">galamm</span>(</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  <span class="at">data =</span> diet,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>  <span class="at">family =</span> families,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  <span class="at">family_mapping =</span> family_mapping,</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>  <span class="at">factor =</span> <span class="fu">list</span>(<span class="st">&quot;loading&quot;</span>),</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>  <span class="at">load.var =</span> <span class="st">&quot;item&quot;</span>,</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">list</span>(loading_matrix),</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>  <span class="at">control =</span> control</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>)</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">#&gt; N = 11, M = 25 machine precision = 2.22045e-16</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co">#&gt; At iterate     0  f=         2148  |proj g|=       122.68</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co">#&gt; At iterate    10  f =       1770.3  |proj g|=        30.656</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co">#&gt; At iterate    20  f =       1467.2  |proj g|=        11.286</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a><span class="co">#&gt; At iterate    30  f =         1413  |proj g|=        4.3102</span></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a><span class="co">#&gt; iterations 38</span></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a><span class="co">#&gt; function evaluations 44</span></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="co">#&gt; segments explored during Cauchy searches 39</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a><span class="co">#&gt; active bounds at final generalized Cauchy point 1</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a><span class="co">#&gt; norm of the final projected gradient 0.001689</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a><span class="co">#&gt; final function value 1406.8</span></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a><span class="co">#&gt; F = 1406.8</span></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a><span class="co">#&gt; final  value 1406.801104 </span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a><span class="co">#&gt; converged</span></span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a><span class="fu">vcov</span>(mod)</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(mod): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a><span class="co">#&gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]</span></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a><span class="co">#&gt;  [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a><span class="co">#&gt;  [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a><span class="co">#&gt;  [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a><span class="co">#&gt;  [4,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a><span class="co">#&gt;  [5,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a><span class="co">#&gt;  [6,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a><span class="co">#&gt;  [7,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a><span class="co">#&gt;  [8,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a><span class="co">#&gt;  [9,]   NA   NA   NA   NA   NA   NA   NA   NA   NA</span></span></code></pre></div>
<p>Looking at the model output again, we see that the random effect
variance is estimated to be exactly zero.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(object, parm = &quot;lambda&quot;): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">#&gt; Warning in vcov.galamm(object, &quot;beta&quot;): Rank deficient Hessian matrix.Could not compute covariance matrix.</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt; Formula: formula</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt;    Data: diet</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#&gt; Control: control</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">#&gt;   2837.6   2892.9  -1406.8  12529.3      730 </span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">#&gt; Scaled residuals: </span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co">#&gt; -10.1374  -0.4390  -0.3523   0.2743  27.3347 </span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt; Lambda:</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt;         loading SE</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">#&gt; lambda1   1.000  .</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="co">#&gt; lambda2   1.000  .</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co">#&gt; lambda3  -1.922  .</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a><span class="co">#&gt; Random effects:</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="co">#&gt;  Groups Name    Variance Std.Dev.</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="co">#&gt;  id     loading 0        0       </span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a><span class="co">#&gt; Number of obs: 742, groups:  id, 333</span></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a><span class="co">#&gt; Fixed effects:</span></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a><span class="co">#&gt; chd           -1.78673         NA      NA       NA</span></span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a><span class="co">#&gt; fiber         17.96179         NA      NA       NA</span></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a><span class="co">#&gt; fiber2        -0.64904         NA      NA       NA</span></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a><span class="co">#&gt; chd:age        0.06685         NA      NA       NA</span></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a><span class="co">#&gt; chd:bus       -0.06894         NA      NA       NA</span></span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a><span class="co">#&gt; fiber:age     -0.20479         NA      NA       NA</span></span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a><span class="co">#&gt; fiber:bus     -1.69628         NA      NA       NA</span></span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a><span class="co">#&gt; chd:age:bus   -0.04937         NA      NA       NA</span></span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a><span class="co">#&gt; fiber:age:bus  0.16092         NA      NA       NA</span></span></code></pre></div>
<p>These types of obviously wrong zero variance estimates are well-known
for users of mixed models <span class="citation">(<a href="#ref-hodgesRichlyParameterizedLinear2013">Hodges 2013</a>)</span>.
We see if increasing the initial value for the variance parameter solves
the issue. This is done with the <code>start</code> argument to
<code>galamm</code>. The start argument requires a named list, with
optional arguments <code>theta</code>, <code>beta</code>,
<code>lambda</code>, and <code>weights</code>, giving initial values for
each of these groups of parameters. In this case <code>theta</code> is
the standard deviation of the random effect, and we increase it to 10 to
see what happens. By default, the initial value equals 1.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">galamm</span>(</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>  <span class="at">data =</span> diet,</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>  <span class="at">family =</span> families,</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>  <span class="at">family_mapping =</span> family_mapping,</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>  <span class="at">factor =</span> <span class="fu">list</span>(<span class="st">&quot;loading&quot;</span>),</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>  <span class="at">load.var =</span> <span class="st">&quot;item&quot;</span>,</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">list</span>(loading_matrix),</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>  <span class="at">start =</span> <span class="fu">list</span>(<span class="at">theta =</span> <span class="dv">10</span>),</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>  <span class="at">control =</span> control</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="co">#&gt; N = 11, M = 25 machine precision = 2.22045e-16</span></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="co">#&gt; At iterate     0  f=       2827.6  |proj g|=       123.31</span></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="co">#&gt; At iterate    10  f =       1764.5  |proj g|=        103.86</span></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co">#&gt; At iterate    20  f =       1623.6  |proj g|=        131.81</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a><span class="co">#&gt; At iterate    30  f =       1447.9  |proj g|=        75.096</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a><span class="co">#&gt; At iterate    40  f =       1400.5  |proj g|=        35.591</span></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a><span class="co">#&gt; At iterate    50  f =       1373.1  |proj g|=        3.3359</span></span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a><span class="co">#&gt; At iterate    60  f =       1372.2  |proj g|=     0.0016541</span></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a><span class="co">#&gt; iterations 60</span></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a><span class="co">#&gt; function evaluations 72</span></span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a><span class="co">#&gt; segments explored during Cauchy searches 61</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a><span class="co">#&gt; active bounds at final generalized Cauchy point 0</span></span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a><span class="co">#&gt; norm of the final projected gradient 0.00165414</span></span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a><span class="co">#&gt; final function value 1372.16</span></span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a><span class="co">#&gt; F = 1372.16</span></span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a><span class="co">#&gt; final  value 1372.160386 </span></span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a><span class="co">#&gt; converged</span></span></code></pre></div>
<p>Now we see that the model converged and that the Hessian is no longer
rank deficient.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; Formula: formula</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt;    Data: diet</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">#&gt; Control: control</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt;   2768.3   2823.6  -1372.2   2002.9      730 </span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">#&gt; Scaled residuals: </span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">#&gt; -258522      -1       0       0      66 </span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">#&gt; Lambda:</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="co">#&gt;         loading      SE</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co">#&gt; lambda1  1.0000       .</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co">#&gt; lambda2  1.0000       .</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co">#&gt; lambda3 -0.1339 0.05121</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a><span class="co">#&gt; Random effects:</span></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a><span class="co">#&gt;  Groups Name    Variance Std.Dev.</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a><span class="co">#&gt;  id     loading 23.64    4.862   </span></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a><span class="co">#&gt; Number of obs: 742, groups:  id, 333</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a><span class="co">#&gt; Fixed effects:</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error  z value   Pr(&gt;|z|)</span></span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a><span class="co">#&gt; chd           -1.91525    0.27229 -7.03373  2.011e-12</span></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a><span class="co">#&gt; fiber         17.94849    0.48686 36.86601 1.620e-297</span></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a><span class="co">#&gt; fiber2         0.22402    0.41783  0.53614  5.919e-01</span></span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a><span class="co">#&gt; chd:age        0.06615    0.05931  1.11531  2.647e-01</span></span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a><span class="co">#&gt; chd:bus       -0.02895    0.34355 -0.08427  9.328e-01</span></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a><span class="co">#&gt; fiber:age     -0.21204    0.10090 -2.10135  3.561e-02</span></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a><span class="co">#&gt; fiber:bus     -1.68303    0.63721 -2.64123  8.261e-03</span></span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a><span class="co">#&gt; chd:age:bus   -0.04999    0.06507 -0.76822  4.424e-01</span></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a><span class="co">#&gt; fiber:age:bus  0.16818    0.11223  1.49854  1.340e-01</span></span></code></pre></div>
</div>
<div id="optimization-with-the-nelder-mead-algorithm" class="section level2">
<h2>Optimization with the Nelder-Mead algorithm</h2>
<p>The Nelder-Mead algorithm is turned on by setting
<code>method = &quot;Nelder-Mead&quot;</code> when calling
<code>galamm_control()</code>. We also turn on reporting every 20th
function evaluation by setting <code>verbose = 1</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">galamm_control</span>(</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>  <span class="at">optim_control =</span> <span class="fu">list</span>(<span class="at">verbose =</span> <span class="dv">1</span>),</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;Nelder-Mead&quot;</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  )</span></code></pre></div>
<p>We provide the estimates obtained with the L-BFGS-B algorithm as
initial values. For this we can use the convenience function
<code>extract_optim_parameters</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">extract_optim_parameters</span>(mod)</span></code></pre></div>
<p>We now fit the model, providing the initial values to the
<code>start</code> argument.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>mod_nm <span class="ot">&lt;-</span> <span class="fu">galamm</span>(</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="at">formula =</span> formula,</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="at">data =</span> diet,</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>  <span class="at">family =</span> families,</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>  <span class="at">family_mapping =</span> family_mapping,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>  <span class="at">factor =</span> <span class="fu">list</span>(<span class="st">&quot;loading&quot;</span>),</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>  <span class="at">load.var =</span> <span class="st">&quot;item&quot;</span>,</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">list</span>(loading_matrix),</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>  <span class="at">control =</span> control,</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>  <span class="at">start =</span> start</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">#&gt; (NM) 20: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">#&gt; (NM) 40: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">#&gt; (NM) 60: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co">#&gt; (NM) 80: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="co">#&gt; (NM) 100: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co">#&gt; (NM) 120: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co">#&gt; (NM) 140: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a><span class="co">#&gt; (NM) 160: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a><span class="co">#&gt; (NM) 180: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a><span class="co">#&gt; (NM) 200: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a><span class="co">#&gt; (NM) 220: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a><span class="co">#&gt; (NM) 240: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a><span class="co">#&gt; (NM) 260: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a><span class="co">#&gt; (NM) 280: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a><span class="co">#&gt; (NM) 300: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a><span class="co">#&gt; (NM) 320: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a><span class="co">#&gt; (NM) 340: f = 1372.16 at    1.84246   -1.91525    17.9485   0.224017   0.066146 -0.0289499  -0.212035   -1.68303 -0.0499864   0.168178  -0.133909</span></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a><span class="co">#&gt; (NM) 360: f = 1372.16 at    1.84247   -1.91525    17.9485   0.223968  0.0661412  -0.028921   -0.21203   -1.68308 -0.0499804   0.168172  -0.133908</span></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a><span class="co">#&gt; (NM) 380: f = 1372.16 at    1.84247   -1.91525    17.9485   0.223979  0.0661419 -0.0289297  -0.212034   -1.68304 -0.0499815   0.168174  -0.133909</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a><span class="co">#&gt; (NM) 400: f = 1372.16 at    1.84247   -1.91525    17.9485   0.223972   0.066143 -0.0289282  -0.212032   -1.68306 -0.0499827   0.168173  -0.133909</span></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a><span class="co">#&gt; (NM) 420: f = 1372.16 at    1.84246   -1.91525    17.9485   0.223982  0.0661428 -0.0289291   -0.21203   -1.68305 -0.0499825    0.16817   -0.13391</span></span></code></pre></div>
<p>The summary output shows that Nelder-Mead found exactly the same
optimum in this particular case, which is not surprising given the
intial values that we provided.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">summary</span>(mod_nm)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="co">#&gt; Formula: formula</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt;    Data: diet</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co">#&gt; Control: control</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co">#&gt;   2768.3   2823.6  -1372.2   2002.9      730 </span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co">#&gt; Scaled residuals: </span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co">#&gt; -258526      -1       0       0      66 </span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co">#&gt; Lambda:</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co">#&gt;         loading      SE</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co">#&gt; lambda1  1.0000       .</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co">#&gt; lambda2  1.0000       .</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a><span class="co">#&gt; lambda3 -0.1339 0.05121</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a><span class="co">#&gt; Random effects:</span></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a><span class="co">#&gt;  Groups Name    Variance Std.Dev.</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a><span class="co">#&gt;  id     loading 23.64    4.862   </span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a><span class="co">#&gt; Number of obs: 742, groups:  id, 333</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a><span class="co">#&gt; Fixed effects:</span></span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error  z value   Pr(&gt;|z|)</span></span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a><span class="co">#&gt; chd           -1.91525    0.27229 -7.03374  2.011e-12</span></span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a><span class="co">#&gt; fiber         17.94850    0.48686 36.86601 1.620e-297</span></span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a><span class="co">#&gt; fiber2         0.22398    0.41783  0.53606  5.919e-01</span></span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a><span class="co">#&gt; chd:age        0.06614    0.05931  1.11527  2.647e-01</span></span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a><span class="co">#&gt; chd:bus       -0.02893    0.34355 -0.08422  9.329e-01</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a><span class="co">#&gt; fiber:age     -0.21203    0.10090 -2.10131  3.561e-02</span></span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a><span class="co">#&gt; fiber:bus     -1.68304    0.63721 -2.64124  8.260e-03</span></span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a><span class="co">#&gt; chd:age:bus   -0.04998    0.06507 -0.76814  4.424e-01</span></span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a><span class="co">#&gt; fiber:age:bus  0.16817    0.11223  1.49847  1.340e-01</span></span></code></pre></div>
</div>
<div id="implementation-details" class="section level2">
<h2>Implementation Details</h2>
<p>At a given set of parameters, the marginal likelihood is evaluated
completely in C++. For solving the penalized iteratively reweighted
least squares problem arising due to the Laplace approximation, we use
sparse matrix methods from the <a href="https://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen C++
template library</a> through the <code>RcppEigen</code> package <span class="citation">(<a href="#ref-batesFastElegantNumerical2013">Bates and
Eddelbuettel 2013</a>)</span>. In order to keep track of the derivatives
throughout this iterative process, we use the <a href="https://autodiff.github.io/">autodiff library</a> <span class="citation">(<a href="#ref-lealAutodiffModernFast2018">Leal
2018</a>)</span>. However, since <code>autodiff</code> natively only
supports dense matrix operations with <code>Eigen</code>, we have
extended this library so that it also supports sparse matrix operations.
This modified version of the <code>autodiff</code> library can be found
at <code>inst/include/autodiff/</code>.</p>
<p>In order to maximize the marginal likelihood, we currently rely on
the <code>optim()</code> function in R. To make use of the fact that
both the marginal likelihood value itself and first derivatives are
returned from the C++ function, we use memoisation, provided by the
<code>memoise</code> package <span class="citation">(<a href="#ref-wickhamMemoiseMemoisationFunctions2021">Wickham et al.
2021</a>)</span>. However, the optimization process still involves
copying all model data between R and C++ for each new set of parameters.
This is potentially an efficiency bottleneck with large datasets,
although with the limited profiling that has been done so far, it seems
like the vast majority of the computation time is spent actually solving
the penalized iteratively reweighted least squares problem in C++.</p>
</div>
<div id="future-improvements" class="section level2">
<h2>Future Improvements</h2>
<p>We aim to perform also the outer optimization loop in C++, to avoid
copying data back and forth between R and C++ during optimization. This
requires finding an off-the-shelf optimization routine which is as good
as the L-BFGS-B implementation provided by <code>optim()</code>, and
which plays well with <code>autodiff</code>.</p>
<p>In addition, the current implementation uses only forward mode
automatic differentiation. In the future, we aim to add backward mode as
an option, as this might turn out to be more efficient for problems with
a large number of variables.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-batesFastElegantNumerical2013" class="csl-entry">
Bates, Douglas M, and Dirk Eddelbuettel. 2013. <span>“Fast and
<span>Elegant Numerical Linear Algebra Using</span> the <span>RcppEigen
Package</span>.”</span> <em>Journal of Statistical Software</em> 52
(February): 1–24. <a href="https://doi.org/10.18637/jss.v052.i05">https://doi.org/10.18637/jss.v052.i05</a>.
</div>
<div id="ref-batesFittingLinearMixedEffects2015" class="csl-entry">
Bates, Douglas M, Martin Mächler, Ben Bolker, and Steve Walker. 2015.
<span>“Fitting <span>Linear Mixed-Effects Models Using</span>
Lme4.”</span> <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-byrdLimitedMemoryAlgorithm1995" class="csl-entry">
Byrd, Richard H., Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995.
<span>“A <span>Limited Memory Algorithm</span> for <span>Bound
Constrained Optimization</span>.”</span> <em>SIAM Journal on Scientific
Computing</em> 16 (5): 1190–1208. <a href="https://doi.org/10.1137/0916069">https://doi.org/10.1137/0916069</a>.
</div>
<div id="ref-hodgesRichlyParameterizedLinear2013" class="csl-entry">
Hodges, James S. 2013. <em>Richly <span>Parameterized Linear Models
Additive</span>, <span>Time Series</span>, and <span>Spatial Models
Using Random Effects</span></em>. 1st ed. Chapman &amp;
<span>Hall</span>/<span>CRC Texts</span> in <span>Statistical
Science</span>. <span>Chapman &amp; Hall</span>.
</div>
<div id="ref-lealAutodiffModernFast2018" class="csl-entry">
Leal, Allan M. M. 2018. <span>“Autodiff, a Modern, Fast and Expressive
<span>C</span>++ Library for Automatic Differentiation.”</span>
</div>
<div id="ref-nelderSimplexMethodFunction1965" class="csl-entry">
Nelder, J. A., and R. Mead. 1965. <span>“A <span>Simplex Method</span>
for <span>Function Minimization</span>.”</span> <em>The Computer
Journal</em> 7 (4): 308–13. <a href="https://doi.org/10.1093/comjnl/7.4.308">https://doi.org/10.1093/comjnl/7.4.308</a>.
</div>
<div id="ref-skaugAutomaticDifferentiationFacilitate2002" class="csl-entry">
Skaug, Hans J. 2002. <span>“Automatic <span>Differentiation</span> to
<span>Facilitate Maximum Likelihood Estimation</span> in <span>Nonlinear
Random Effects Models</span>.”</span> <em>Journal of Computational and
Graphical Statistics</em> 11 (2): 458–70.
</div>
<div id="ref-sorensenLongitudinalModelingAgeDependent2023" class="csl-entry">
Sørensen, Øystein, Anders M. Fjell, and Kristine B. Walhovd. 2023.
<span>“Longitudinal <span>Modeling</span> of <span>Age-Dependent Latent
Traits</span> with <span>Generalized Additive Latent</span> and
<span>Mixed Models</span>.”</span> <em>Psychometrika</em> 88 (2):
456–86. <a href="https://doi.org/10.1007/s11336-023-09910-z">https://doi.org/10.1007/s11336-023-09910-z</a>.
</div>
<div id="ref-wickhamMemoiseMemoisationFunctions2021" class="csl-entry">
Wickham, Hadley, Jim Hester, Winston Chang, Kirill Müller, and Daniel
Cook. 2021. <em>Memoise: ’Memoisation’ of Functions</em>. Manual.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
